#Data_pipeline_AirFlow_Docker
#It contains end to end implementation
#The ETL process is carried out with twitter data. Through elevated access developer is able to get the data. Data can be used for analysis which is 
#covered in the next project.
#So the airflow pipeline helps in loading data from twitter on a daily basis. 
#Docker is used to build the process, trigger airflow lib and start runing it.
#![Alt text](https://github.com/ShazzAbhishek/Data_pipeline_AirFlow_Docker/blob/main/server-start.png)
#![Alt text](https://github.com/ShazzAbhishek/Data_pipeline_AirFlow_Docker/blob/main/dag-tasks.png)
